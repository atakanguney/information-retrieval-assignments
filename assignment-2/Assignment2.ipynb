{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE:** Do not change signatures of methods defined below. Those methods will be used while grading your homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from collections import namedtuple\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from heapq import nlargest\n",
    "from itertools import islice\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIE_ID_FILE = \"movie_ids.csv\"\n",
    "ALL_MOVIE_CONTENTS = \"all_movie_contents.pickle\"\n",
    "BASE_URL = \"https://www.imdb.com/title/\"\n",
    "NUMBER_WORDS = 5000\n",
    "NUMBER_RECS = 10\n",
    "STOPWORDS = []# ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    \"\"\"\n",
    "    Read csv file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        File to read\n",
    "    \"\"\"\n",
    "    with open(path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    return [line.strip() for line in lines if line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_content(imdb_id):\n",
    "    \"\"\"Get HTML content of movie\n",
    "    \"\"\"\n",
    "    url = BASE_URL + imdb_id\n",
    "    response = requests.get(url)\n",
    "    if response.status_code >= 400:\n",
    "        raise ValueError(\"Something went wrong in request !: {}, {}\".format(url, response.status_code))\n",
    "\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_title(html_content):\n",
    "    # TODO: Write doc-string\n",
    "    pattern = re.compile(r'<div\\s+?class\\s*?=\\s*?\"title_wrapper\".*?'\n",
    "                         + r'<h1\\s*?class\\s*?=\\s*?\".*?\">(.*?)&nbsp;', re.DOTALL)\n",
    "    match = pattern.search(html_content)\n",
    "    \n",
    "    return match.group(1).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rec_item(html_content):\n",
    "    # TODO: Write doc-string\n",
    "    pattern = re.compile(r'<div\\s+?class\\s*?=\\s*?\"(?:rec_item|rec_item rec_selected)\" data-info=\"\" data-spec=\".*?\" data-tconst=\"(.*?)\">')\n",
    "    for match in pattern.finditer(html_content):\n",
    "        yield match.group(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_recommendations(html_content):\n",
    "    # TODO: Write doc-string\n",
    "    return list(find_rec_item(html_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_storyline(html_content):\n",
    "    # TODO: Write doc-string\n",
    "    pattern = re.compile(r'<h2>\\s*?Storyline\\s*?</h2>.*?'\n",
    "                         + r'<span>(.*?)</span>', re.DOTALL)\n",
    "\n",
    "    match = pattern.search(html_content)\n",
    "\n",
    "    return match.group(1).strip() # + \" \" + match.group(2).strip() + \" \" + match.group(3).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_contents(imdb_id):\n",
    "    \"\"\"\n",
    "    Gets an imdb id and returns its title, storyline, list of IMDB recommendations respectively.\n",
    "    \"\"\"\n",
    "    html_content = get_html_content(imdb_id)\n",
    "    try:\n",
    "        title = find_title(html_content)\n",
    "        storyline = find_storyline(html_content)\n",
    "        recommendations = find_recommendations(html_content)\n",
    "    except AttributeError as e:\n",
    "        print(html_content)\n",
    "        raise AttributeError\n",
    "\n",
    "    return title, storyline, recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping(path, pickle_path, restore=False):\n",
    "    # TODO: Write doc-string\n",
    "    movie_ids = read_csv(path)\n",
    "    if restore:\n",
    "        with open(pickle_path, \"rb\") as f:\n",
    "            all_movie_contents = pickle.load(f)\n",
    "    else:\n",
    "        all_movie_contents = {}\n",
    "    for i, movie_id in enumerate(movie_ids):\n",
    "        if i % 20 == 0:\n",
    "            print(\"Movie id: {}\".format(movie_id))\n",
    "            print(\"Number of collected movie: {}\".format(len(all_movie_contents)))\n",
    "        if movie_id in all_movie_contents:\n",
    "            continue\n",
    "        while True:\n",
    "            try:\n",
    "                title, storyline, recs = get_movie_contents(movie_id)\n",
    "            except ConnectionError as e:\n",
    "                time.sleep(4)\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                with open(pickle_path, \"wb\") as f:\n",
    "                    pickle.dump(all_movie_contents, f)\n",
    "                raise e\n",
    "            break\n",
    "\n",
    "        movie_content = MovieContent(\n",
    "            title=title,\n",
    "            storyline=storyline,\n",
    "            recommendations=recs\n",
    "        )\n",
    "        all_movie_contents[movie_id] = movie_content\n",
    "        for rec_id in recs:\n",
    "            if rec_id in all_movie_contents:\n",
    "                continue\n",
    "            while True:\n",
    "                try:\n",
    "                    rec_title, rec_storyline, rec_recs = get_movie_contents(rec_id)\n",
    "                except ConnectionError as e:\n",
    "                    time.sleep(10)\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    with open(pickle_path, \"wb\") as f:\n",
    "                        pickle.dump(all_movie_contents, f)\n",
    "                    raise e\n",
    "                break\n",
    "\n",
    "            rec_movie_content = MovieContent(\n",
    "                title=rec_title,\n",
    "                storyline=rec_storyline,\n",
    "                recommendations=rec_recs\n",
    "            )\n",
    "            all_movie_contents[rec_id] = rec_movie_content\n",
    "\n",
    "    with open(pickle_path, \"wb\") as f:\n",
    "        pickle.dump(all_movie_contents, f)\n",
    "\n",
    "    return all_movie_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MovieContent = namedtuple(\"MovieContent\", \"title storyline recommendations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_movie_contents = scraping(MOVIE_ID_FILE, ALL_MOVIE_CONTENTS, restore=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ALL_MOVIE_CONTENTS, \"rb\") as f:\n",
    "    all_movie_contents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_htlm_tags(doc):\n",
    "    \"\"\"Clean links\"\"\"\n",
    "    pattern = re.compile(r\"<[/]?a.*?>\", re.DOTALL)\n",
    "    return re.sub(pattern, \"\", doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc, stopwords):\n",
    "    \"\"\"Tokenize document\"\"\"\n",
    "    doc = doc.lower()\n",
    "    doc = remove_htlm_tags(doc)\n",
    "    pattern = re.compile(r\"\\w+\")\n",
    "    \n",
    "    return [match.group() for match in pattern.finditer(doc) if match and match.group() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_corpus(contents, stopwords):\n",
    "    \"\"\"Construct corpus with given movie contents\"\"\"\n",
    "    return {\n",
    "        movie_id: tokenize(content.storyline, stopwords)\n",
    "        for movie_id, content in contents.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_vocabulary(corpus):\n",
    "    \"\"\"Construct vocabulary by given corpus\"\"\"\n",
    "    vocab = {}\n",
    "    for doc_id, doc in corpus.items():\n",
    "        for word, count in dict(Counter(doc)).items():\n",
    "            vocab.setdefault(word, []).append((doc_id, count))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take(n, iterable):\n",
    "    return dict(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occurences(vocabulary):\n",
    "    return {\n",
    "        word: reduce(lambda total_count, doc_count: total_count + doc_count[1], doc_count_list, 0)\n",
    "        for word, doc_count_list in vocabulary.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_words(k, vocabulary):\n",
    "    \"\"\"Returns most frequent k words\"\"\"\n",
    "    vocab_occurences = get_occurences(vocabulary)\n",
    "    return sorted(vocab_occurences, key=lambda x: vocab_occurences[x], reverse=True)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(sparse_vector):\n",
    "    \"\"\"Calculate L2 norm of given sparse vector\"\"\"\n",
    "    return (reduce(lambda sum_, score: sum_ + score**2, sparse_vector.values(), 0))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2vec(vocabulary, top_k_words, num_docs):\n",
    "    \"\"\"Compute document vectors\"\"\"\n",
    "    doc2vec = {}\n",
    "    for word in top_k_words:\n",
    "        doc_count_list = vocabulary[word]\n",
    "        document_freq = len(doc_count_list)\n",
    "        for doc, term_freq in doc_count_list:\n",
    "            doc2vec.setdefault(doc, {}).update({word: term_freq * (log(num_docs) - log(document_freq))})\n",
    "\n",
    "\n",
    "    for doc_id, raw_tf_idf_vector in doc2vec.items():\n",
    "        vector_norm = norm(raw_tf_idf_vector)\n",
    "        doc2vec[doc_id] = {\n",
    "            word: raw_tf_idf / vector_norm\n",
    "            for word, raw_tf_idf in raw_tf_idf_vector.items()\n",
    "        }\n",
    "        \n",
    "    return doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_vector(text):\n",
    "    tokens = tokenize(text, STOPWORDS)\n",
    "    raw_vector = {\n",
    "        word: tokens.count(word)\n",
    "        for word in set(tokens)\n",
    "    }\n",
    "    vector_norm = norm(raw_vector)\n",
    "    return {\n",
    "        word: score / vector_norm\n",
    "        for word, score in raw_vector.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_dot_product(sparse_vec_1, sparse_vec_2):\n",
    "    common_words = set(sparse_vec_1).intersection(set(sparse_vec_2))\n",
    "    result = 0\n",
    "    for word in common_words:\n",
    "        result += sparse_vec_1[word] * sparse_vec_2[word]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_k_similar(k, text_vector, doc_vec):\n",
    "    similarities = {\n",
    "        doc_id: sparse_dot_product(doc_vector, text_vector)\n",
    "        for doc_id, doc_vector in doc_vec.items()\n",
    "    }\n",
    "    return list(nlargest(k, similarities, key=similarities.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = construct_corpus(all_movie_contents, STOPWORDS)\n",
    "\n",
    "vocabulary = construct_vocabulary(corpus)\n",
    "\n",
    "vocab_occurences = get_occurences(vocabulary)\n",
    "\n",
    "top_n_words = top_k_words(NUMBER_WORDS, vocabulary)\n",
    "\n",
    "num_docs = len(corpus)\n",
    "\n",
    "doc_vec = doc2vec(vocabulary, top_n_words, num_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = NUMBER_RECS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(imdb_id):\n",
    "    \"\"\"\n",
    "    Gets an imdb id and returns a list of recommended movie ids for that movie. \n",
    "    \"\"\"\n",
    "    storyline = all_movie_contents[imdb_id].storyline\n",
    "    \n",
    "    text_vector = construct_vector(storyline)\n",
    "    \n",
    "    return get_most_k_similar(K, text_vector, doc_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(rec_movie_ids, relevant_movie_ids):\n",
    "    \"\"\"Compute Precision\"\"\"\n",
    "    count = 0\n",
    "    for movie_id in relevant_movie_ids:\n",
    "        if movie_id in rec_movie_ids:\n",
    "            count += 1\n",
    "\n",
    "    return count / (len(rec_movie_ids) + 10**-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(rec_movie_ids, relevant_movie_ids):\n",
    "    \"\"\"Compute Recall\"\"\"\n",
    "    count = 0\n",
    "    for movie_id in rec_movie_ids:\n",
    "        if movie_id in relevant_movie_ids:\n",
    "            count += 1\n",
    "            \n",
    "    return count / (len(relevant_movie_ids) + 10**-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommendations(rec_movie_ids, relevant_movie_ids, K):\n",
    "    \"\"\"\n",
    "    Gets list of recommended and relevant movie ids and K value.\n",
    "    \n",
    "    Returns precision, recall, F1 values for K respectively. \n",
    "    \"\"\"\n",
    "    prec = precision(rec_movie_ids, relevant_movie_ids) \n",
    "    rec = recall(rec_movie_ids, relevant_movie_ids)\n",
    "    F_1 = 2 * prec * rec / (prec + rec + 10**(-8))\n",
    "    \n",
    "    return prec, rec, F_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_precision(rec_movie_ids, relevant_movie_ids):\n",
    "    \"\"\"Calculates average precision\"\"\"\n",
    "    sum_prec = 0\n",
    "    relevant_count = 0\n",
    "    for i, rec in enumerate(rec_movie_ids):\n",
    "        if rec in relevant_movie_ids:\n",
    "            relevant_count += 1\n",
    "            sum_prec += relevant_count / (i + 1)\n",
    "    return sum_prec / (len(relevant_movie_ids) + 10**-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ids = read_csv(MOVIE_ID_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.1111111109876543, F-1: 0.10526315279778417\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.12499999984374999, F-1: 0.11111110604938293\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.16666666638888888, F-1: 0.12499999515625017\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.6999999992999999, Recall: 0.5833333328472222, F-1: 0.6363636308264463\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.1111111109876543, F-1: 0.10526315279778417\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.5999999993999999, Recall: 0.9999999983333333, F-1: 0.7499999943750001\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.5999999993999999, Recall: 0.4999999995833333, F-1: 0.5454545399999999\n",
      "Precision: 0.5999999993999999, Recall: 0.4999999995833333, F-1: 0.5454545399999999\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.14285714265306124, F-1: 0.11764705384083066\n",
      "Precision: 0.6999999992999999, Recall: 0.5833333328472222, F-1: 0.6363636308264463\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.1111111109876543, F-1: 0.10526315279778417\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.5999999993999999, Recall: 0.4999999995833333, F-1: 0.5454545399999999\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.5999999993999999, Recall: 0.4999999995833333, F-1: 0.5454545399999999\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.16666666638888888, F-1: 0.12499999515625017\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.6999999992999999, Recall: 0.5833333328472222, F-1: 0.6363636308264463\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.7999999992, Recall: 0.666666666111111, F-1: 0.7272727216528925\n",
      "Precision: 0.6999999992999999, Recall: 0.5833333328472222, F-1: 0.6363636308264463\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.0999999999, Recall: 0.0999999999, F-1: 0.09999999490000026\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.2857142853061225, F-1: 0.23529411252595167\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.14285714265306124, F-1: 0.11764705384083066\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.2857142853061225, F-1: 0.23529411252595167\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.0999999999, F-1: 0.09999999490000026\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.0999999999, Recall: 0.1111111109876543, F-1: 0.10526315279778417\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.09090909082644627, F-1: 0.09523809015873042\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.6999999992999999, Recall: 0.5833333328472222, F-1: 0.6363636308264463\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.5999999993999999, Recall: 0.4999999995833333, F-1: 0.5454545399999999\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.6999999992999999, Recall: 0.5833333328472222, F-1: 0.6363636308264463\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.14285714265306124, F-1: 0.11764705384083066\n",
      "Precision: 0.0999999999, Recall: 0.0999999999, F-1: 0.09999999490000026\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.5999999993999999, Recall: 0.4999999995833333, F-1: 0.5454545399999999\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.49999999949999996, Recall: 0.7142857132653061, F-1: 0.5882352885813149\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.7999999992, Recall: 0.666666666111111, F-1: 0.7272727216528925\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.249999999375, F-1: 0.14285713857142868\n",
      "Precision: 0.5999999993999999, Recall: 0.4999999995833333, F-1: 0.5454545399999999\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.09090909082644627, F-1: 0.09523809015873042\n",
      "Precision: 0.0999999999, Recall: 0.09090909082644627, F-1: 0.09523809015873042\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.29999999969999996, F-1: 0.29999999470000005\n",
      "Precision: 0.0999999999, Recall: 0.1111111109876543, F-1: 0.10526315279778417\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.16666666638888888, F-1: 0.12499999515625017\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.1111111109876543, F-1: 0.10526315279778417\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.5999999993999999, Recall: 0.4999999995833333, F-1: 0.5454545399999999\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.5999999993999999, Recall: 0.4999999995833333, F-1: 0.5454545399999999\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.0999999999, Recall: 0.0999999999, F-1: 0.09999999490000026\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.18181818165289254, F-1: 0.19047618530612256\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.5999999993999999, Recall: 0.4999999995833333, F-1: 0.5454545399999999\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.37499999953124996, F-1: 0.3333333280246914\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.14285714265306124, F-1: 0.11764705384083066\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.49999999949999996, Recall: 0.5555555549382716, F-1: 0.5263157839335181\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.5999999993999999, Recall: 0.4999999995833333, F-1: 0.5454545399999999\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.0999999999, Recall: 0.14285714265306124, F-1: 0.11764705384083066\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.1999999998, F-1: 0.19999999480000014\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.1999999996, F-1: 0.13333332871111125\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.7999999992, Recall: 0.666666666111111, F-1: 0.7272727216528925\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.5999999993999999, Recall: 0.4999999995833333, F-1: 0.5454545399999999\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.5999999993999999, Recall: 0.4999999995833333, F-1: 0.5454545399999999\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.1999999996, F-1: 0.13333332871111125\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.24999999968749997, F-1: 0.22222221703703712\n",
      "Precision: 0.6999999992999999, Recall: 0.5833333328472222, F-1: 0.6363636308264463\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.1999999998, Recall: 0.16666666652777776, F-1: 0.181818176694215\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.3999999996, Recall: 0.3333333330555555, F-1: 0.3636363583471074\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.5999999993999999, Recall: 0.4999999995833333, F-1: 0.5454545399999999\n",
      "Precision: 0.29999999969999996, Recall: 0.49999999916666665, F-1: 0.37499999484375\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.49999999949999996, Recall: 0.41666666631944443, F-1: 0.4545454491735537\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.29999999969999996, Recall: 0.24999999979166665, F-1: 0.2727272675206612\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n",
      "Precision: 0.3999999996, Recall: 0.7999999984, F-1: 0.5333333281777778\n",
      "Precision: 0.0999999999, Recall: 0.08333333326388888, F-1: 0.09090908586776886\n"
     ]
    }
   ],
   "source": [
    "precs = []\n",
    "recalls = []\n",
    "f_1s = []\n",
    "for movie_id in movie_ids:\n",
    "    rec_movie_ids = recommend(movie_id)\n",
    "    relevant_movie_ids = all_movie_contents[movie_id].recommendations\n",
    "    prec, rec, f_1 = evaluate_recommendations(rec_movie_ids, relevant_movie_ids, NUMBER_RECS)\n",
    "    precs.append(prec)\n",
    "    recalls.append(rec)\n",
    "    f_1s.append(f_1)\n",
    "    if prec > 0:\n",
    "        print(\"Precision: {}, Recall: {}, F-1: {}\".format(prec, rec, f_1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Average Precision :0.039216018491483526\n"
     ]
    }
   ],
   "source": [
    "sum_ap = 0\n",
    "for movie_id in movie_ids:\n",
    "    rec_movie_ids = recommend(movie_id)\n",
    "    if not rec_movie_ids:\n",
    "        print(movie_id)\n",
    "    relevant_movie_ids = all_movie_contents[movie_id].recommendations\n",
    "    sum_ap += average_precision(rec_movie_ids, relevant_movie_ids)\n",
    "print(\"Mean Average Precision :{}\".format(sum_ap / len(movie_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
